pkgbuild::compile_dll() # see note below
roxygen2::roxygenise(load = "source")
t <- c(6.5, 4, 4.5, 5)
Wobs <- t
class <- apply(Wobs, 1, classify_func)
#'Classify river for expert framework
#'
#'@param Wobs observed widths matrix
classify_func <- function(Wobs) {
lwbar <- mean(log(Wobs), na.rm=TRUE)#apply(log(Wobs), 1, mean, na.rm = TRUE)
lwsd <- sd(log(Wobs), na.rm= TRUE)#apply(log(Wobs), 1, sd, na.rm = TRUE)
maxWidth = 6.5
classes <- c(2.641197894, 3.143289838,3.376904689,
3.548754946,3.823191792,4.150094577,
4.626687029,5.248706866) #median width of each river type
ifelse(lwbar > maxWidth, 100,
ifelse(lwsd >= 0.45, 9, which.min(abs(classes-lwbar)))) #100 for big rivers, 9 for width-variable rivers
}
class <- apply(Wobs, 1, classify_func)
wobs <- rbind(t, c(4.5.6), c(4.5, 4.7, 4.8))
wobs <- rbind(t, c(4,5,6), c(4.5, 4.7, 4.8))
View(wobs)
class <- apply(Wobs, 1, classify_func)
wobs <- cbind(c(4,5,6), c(4, 4.5, 6), c(7,6,7))
class <- apply(Wobs, 1, classify_func)
Wobs <- wobs
class <- apply(Wobs, 1, classify_func)
#expert classification
temp <- c(0.281116498,
0.24873163,
0.233806573,
0.221609934,
0.190969495,
0.186128473,
0.145874141,
0.15322105,
0.405)
lwsd <- apply(log(Wobs), 1, function(x) sd(x, na.rm = TRUE))
b_hat <- rep(ifelse(class != 100, temp[class], 0.0569 + 0.3822 * lwsd), nrow(Wobs)) #repeat by sptial unit
b_hat
b_hat <- ifelse(class != 100, temp[class], 0.0569 + 0.3822 * lwsd), nrow(Wobs) #repeat by sptial unit
b_hat <- ifelse(class != 100, temp[class], 0.0569 + 0.3822 * lwsd), nrow(Wobs)) #repeat by sptial unit
b_hat <- ifelse(class != 100, temp[class], 0.0569 + 0.3822 * lwsd) #repeat by sptial unit
b_hat
class <- c(1,1,3)
b_hat <- ifelse(class != 100, temp[class], 0.0569 + 0.3822 * lwsd) #repeat by sptial unit
lowerbound_b <- ifelse(class != 100, temp[class], 0.000182357)
temp <- c(0.01904573,
0.016895241,
0.009206385,
0.009206385,
0.009206385,
0.009634045,
0.008909195,
0.000182357,
0.029)
lowerbound_b <- ifelse(class != 100, temp[class], 0.000182357)
lowerbound_b <- min(lowerbound_b)
temp <- c(0.127044741,
0.121791926,
0.116980495,
0.120133338,
0.11851495,
0.131447085,
0.123924935,
0.117431499,
0.11)
class <- apply(Wobs, 1, classify_func)
b_sd <- ifelse(class != 100, temp[class], 0.068077044)
#Expert classification
temp <- c(4.235554731,
4.890349128,
5.036952602,
5.347107531,
5.768320996,
6.488444764,
7.222566019,
8.496990484,
4.394)
class <- apply(Wobs, 1, classify_func)
logA0_hat <- ifelse(class != 100, temp[class], -0.2918 + 1.6930 * lwbar - 0.1887 * lwsd) #repeat for each sptial unit
class <- c(1,1,4)
logA0_hat <- ifelse(class != 100, temp[class], -0.2918 + 1.6930 * lwbar - 0.1887 * lwsd) #repeat for each sptial unit
pkgbuild::compile_dll() # see note below
roxygen2::roxygenise(load = "source")
pkgbuild::compile_dll() # see note below
roxygen2::roxygenise(load = "source")
apples
library(pkgdown)
# Run once to configure your package to use pkgdown
usethis::use_pkgdown()
# Run to build the website
pkgdown::build_site()
pkgbuild::compile_dll() # see note below
Roxygen2::roxygenise(load = "source")
library(roxygen2)
roxygen2::roxygenise(load = "source")
# Run once to configure your package to use pkgdown
usethis::use_pkgdown()
# Run to build the website
pkgdown::build_site()
# Run to build the website
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
#Set up ----------------------------------------------------------------------
#package check
packages = c("rgdal", "rgeos", "ggfortify", "tidyverse", "spdplyr", "RColorBrewer", "cowplot", "sf")
package.check <- lapply(packages, FUN = function(x) {
if (!require(x, character.only = TRUE)) {
install.packages(x, dependencies = TRUE)
library(x, character.only = TRUE)
}
})
#verify they are loaded
search()
#set up environment
setwd("C:/Users/craig/Box Sync/Ongoing Projects/Watershed_Rules_of_Life/working_drive_4_watersheds/CT")
#Necessary Functions------------------------------------------------------------
#'Not in' function
`%notin%` <- Negate(`%in%`)
#GHG Transport Model (in channel)
transportModel_inchannel <- function(StartFlag, Divergence, fromNode, HRT, ticker, order, startOrder, Cnaught, k, rivSwitch, waterbody){
if(order < startOrder){#set all orders upstream of starting order to NA
Q[ticker] <- NA
output <- NA
return(output)
}
else{ #if not upstream of selected order
upstreamIndexes <- which(toNode_vec == fromNode) #get directly upstream reaches
StartFlag <- ifelse(order == startOrder && startOrder %notin% StreamOrde_vec[upstreamIndexes], 1, StartFlag) #set startflag at any stream at startorder that isn't downstream of an equally ordered stream
if (StartFlag == 1 || Divergence == 1 || all(is.na(hrt_vec[upstreamIndexes]))==1){ #if headwater, divergent reach, or all upstream reaches have HRT of NA (Q of 0) then run transport model using Cnaught
return(Cnaught*exp(-(k)*HRT*3600)) #3600 to convert hrs to sec
}
else if (Divergence == 1) { #642 total reaches THIS IS NOT CURRENTLY RUNNING B/C
return(NA)
}
else {
weightedUpstreamConc <- weighted.mean(transported[upstreamIndexes], Q[upstreamIndexes], na.rm=TRUE)
#lakes/reservoirs 'turned off'
if (rivSwitch == 1 & waterbody[i] == 'Lake/Reservoir') {#if reach is a lake and we are 'skipping lakes', just set avg upstream concentration to this one,i.e. don't run the model
return(weightedUpstreamConc)
}
else {
return(weightedUpstreamConc*exp(-(k)*HRT*3600)) #run transport model at current reach (3600 to convert hrs to sec)
}
}
}
}
#water HRT (accounts for other HRT calcualtion for lakes)
restimeWater <- function(Vol,lengthKm, v, Q, waterbody){
if (Q == 0){
return(NA) #zero flow means no HRT
}
else if (waterbody == 'Lake/Reservoir') {
return(((Vol)/(Q))/3600) #if lake throughflow line, calculate lake HRT for each throughflow line
}
else if (waterbody == 'River'){
return(((lengthKm*1000)/(v))/3600) #if normal flowline, calcuate reach HRT
}
else{ #just in case, but this will never actually run
return(NA)
}
}
#GHG Evasion Model (in channel)
evasionModel_inchannel <- function(StartFlag, Divergence, fromNode, HRT, ticker, order, startOrder, Cnaught, k, rivSwitch, waterbody){
if(order < startOrder){#set all orders upstream of starting order to NA
Q[ticker] <- NA
output <- NA
return(output)
}
else{ #if not upstream of selected order
upstreamIndexes <- which(toNode_vec == fromNode) #get directly upstream reaches
StartFlag <- ifelse(order == startOrder && startOrder %notin% StreamOrde_vec[upstreamIndexes], 1, StartFlag) #set startflag at any stream at startorder that isn't downstream of an equally ordered stream
if (StartFlag == 1 || Divergence == 1 || all(is.na(hrt_vec[upstreamIndexes]))==1){ #if divergent reach or starting order, run transport model using Cnaught
return(Cnaught - (Cnaught*exp(-(k)*HRT*3600))) #3600 to convert hrs to sec
}
else { #if normal, downstream reach
weightedUpstreamConc <- weighted.mean(transported[upstreamIndexes], Q[upstreamIndexes], na.rm=TRUE)
#lakes/reservoirs 'turned off'
if (rivSwitch == 1 & waterbody[i] == 'Lake/Reservoir') {#if reach is a lake and we are 'skipping lakes', just set avg upstream concentration to this one,i.e. don't run the model
return(0)
}
else {
return(weightedUpstreamConc - (weightedUpstreamConc*exp(-(k)*HRT*3600))) #run transport model at current reach (3600 to convert hrs to sec)
}
}
}
}
#GHG dilution Model (in channel)
dilutionModel_inchannel <- function(StartFlag, Divergence, fromNode, ticker, order, startOrder){
if(order < startOrder){#set all orders upstream of starting order to NA
Q[ticker] <- NA
output <- NA
return(output)
}
else{ #if not upstream of selected order
upstreamIndexes <- which(toNode_vec == fromNode) #get directly upstream reaches
StartFlag <- ifelse(order == startOrder && startOrder %notin% StreamOrde_vec[upstreamIndexes], 1, StartFlag) #set startflag at any stream at startorder that isn't downstream of an equally ordered stream
if (StartFlag == 1 || Divergence == 2 || all(is.na(hrt_vec[upstreamIndexes]))==1){ #if divergent reach or starting order, run transport model using Cnaught
return(0) #no dilution due to joining streams if headwater/divergent reach
}
else { #GHG that has been 'diluted away' thanks to intersecting streams increaing the volume of water
weightedUpstreamConc <- weighted.mean(transported[upstreamIndexes], Q[upstreamIndexes], na.rm=TRUE)
totalUpstreamConc <- sum(transported[upstreamIndexes], na.rm=TRUE)
return(totalUpstreamConc - weightedUpstreamConc)
}
}
}
#Cummulative Distance Travelled
distAccumulator <- function(StartFlag, Divergence, fromNode, reachLength, ticker, order, startOrder){
if(order < startOrder){#set all orders upstream of tarting order to NA
Q[ticker] <- NA
output <- NA
return(output)
}
else{ #if not above selected order
upstreamIndexes <- which(toNode_vec == fromNode) #get directly upstream reaches
StartFlag <- ifelse(order == startOrder && startOrder %notin% StreamOrde_vec[upstreamIndexes], 1, StartFlag) #set startflag at any stream at startorder that isn't downstrea of an equally ordered stream
if (StartFlag == 1 || Divergence == 2){
return(reachLength)
}
else {
weightedUpstreamHRT <- weighted.mean(distTravelled_m[upstreamIndexes], Q[upstreamIndexes], na.rm=TRUE) #weight incoming values by Q, because bigger streams will input more water into given reach than smaller tribs
return(sum(weightedUpstreamHRT, reachLength, na.rm = TRUE)) #add to current reach's reachLength
}
}
}
#Assign binned gas Transfer velocities using lake surface area as predictor. From Raymond et al. 2013 and someone else.
lakek600_func <- function(lakeArea){ #km2
classes <- c(0.1, 1, 10)
output <- ifelse(lakeArea <= classes[1], 0.54,
ifelse(lakeArea <= classes[2], 1.16,
ifelse(lakeArea <- classes[3], 1.32, 1.90))) #m/day
return(output)
}
#prepare shapefiles/dataset for analysis------------------------------------------------------------------------
if (munge == 1) {
#import necessary data from NHD HR------------------------------------------
NHD_HR_lines <- readOGR(dsn = "C:\\Users\\cbrinkerhoff\\Box Sync\\Ongoing Projects\\Watershed_Rules_of_Life\\Study_watersheds\\NHDPlus_HR\\NHDPLUS_H_0108_HU4_GDB(1)\\NHDPLUS_H_0108_HU4_GDB.gdb", layer = "NHDFlowline") #flowlines clipped to basin
NHD_HR_lakes <- readOGR(dsn = "C:\\Users\\cbrinkerhoff\\Box Sync\\Ongoing Projects\\Watershed_Rules_of_Life\\Study_watersheds\\NHDPlus_HR\\NHDPLUS_H_0108_HU4_GDB(1)\\NHDPLUS_H_0108_HU4_GDB.gdb", layer = "NHDWaterbody") #waterbodies clipped to basin
NHD_HR_lakes <- filter(NHD_HR_lakes, FType == 436 | FType == 390) #lakes/reservoirs only
NHD_HR_EROM <- sf::st_read(dsn = "C:\\Users\\cbrinkerhoff\\Box Sync\\Ongoing Projects\\Watershed_Rules_of_Life\\Study_watersheds\\NHDPlus_HR\\NHDPLUS_H_0108_HU4_GDB(1)\\NHDPLUS_H_0108_HU4_GDB.gdb", layer = "NHDPlusEROMMA")
NHD_HR_VAA <- sf::st_read(dsn = "C:\\Users\\cbrinkerhoff\\Box Sync\\Ongoing Projects\\Watershed_Rules_of_Life\\Study_watersheds\\NHDPlus_HR\\NHDPLUS_H_0108_HU4_GDB(1)\\NHDPLUS_H_0108_HU4_GDB.gdb", layer = "NHDPlusFlowlineVAA")
lakeVols <- read.csv('C:\\Users\\cbrinkerhoff\\Box Sync\\Ongoing Projects\\Watershed_Rules_of_Life\\working_drive_4_watersheds\\CT\\lakeVolumes.txt')
NHD_HR_merged <- left_join(NHD_HR_lines, NHD_HR_VAA, by='NHDPlusID')
NHD_HR_merged <- left_join(NHD_HR_merged, NHD_HR_EROM, by='NHDPlusID')
NHD_HR_merged.df <- NHD_HR_merged@data
lakes <- NHD_HR_lakes@data
lakes <- left_join(lakes, lakeVols, by=c('NHDPlusID'='ID'))
lakes <- select(lakes, Permanent_Identifier, NHDPlusID, AreaSqKm, lVol)
NHD_HR_merged.df <- left_join(NHD_HR_merged.df, lakes, by= c('WBArea_Permanent_Identifier'= 'Permanent_Identifier'))
colnames(NHD_HR_merged.df)[89] <- 'LakeAreaSqKm'
colnames(NHD_HR_merged.df)[90] <- 'LakeVol_m3'
colnames(NHD_HR_merged.df)[16] <- 'NHDPlusID'
NHD_HR_merged.df$CaelVol_m3 <- 0.533 * (NHD_HR_merged.df$LakeAreaSqKm*1000000)^1.204 #Cael et al. 2016
NHD_HR_merged.df <- select(NHD_HR_merged.df, Permanent_Identifier, NHDPlusID, LengthKM, FlowDir, WBArea_Permanent_Identifier,
StreamOrde, FromNode, ToNode, HydroSeq, Divergence, StartFlag, AreaSqKm.x, TotDASqKm, DivDASqKm,
Slope, QEMA, VEMA, LakeAreaSqKm, LakeVol_m3, CaelVol_m3)
NHD_HR_merged.df$LakeVol_m3 <- ifelse(NHD_HR_merged.df$LakeAreaSqKm < 0.1, #if lake is too small (< 0.1 skm), then run Cael's Adriodacks model as its the most regionally similar
ifelse(NHD_HR_merged.df$LakeAreaSqKm == 0, 0, (0.425*(NHD_HR_merged.df$LakeAreaSqKm*1000000)^1.239)), NHD_HR_merged.df$LakeVol_m3)
sumThroughFlow <- filter(NHD_HR_merged.df, is.na(WBArea_Permanent_Identifier)==0) %>%
group_by(WBArea_Permanent_Identifier) %>%
summarise(sumThroughFlow = sum(LengthKM))
NHD_HR_merged.df <- left_join(NHD_HR_merged.df, sumThroughFlow, by='WBArea_Permanent_Identifier')
NHD_HR_merged.df$lakePercent <- NHD_HR_merged.df$LengthKM / NHD_HR_merged.df$sumThroughFlow
NHD_HR_merged.df$frac_lakeVol_m3 <- NHD_HR_merged.df$LakeVol_m3 * NHD_HR_merged.df$lakePercent
NHD_HR_merged.df$frac_CaelVol_m3 <- NHD_HR_merged.df$CaelVol_m3 * NHD_HR_merged.df$lakePercent
NHD_HR_merged.df$waterbody <- ifelse(is.na(NHD_HR_merged.df$WBArea_Permanent_Identifier)==0 & is.na(NHD_HR_merged.df$LakeAreaSqKm) == 0 & NHD_HR_merged.df$LakeAreaSqKm > 0, 'Lake/Reservoir', 'River')
write.table(NHD_HR_merged.df, 'NHD_gasTransfer_CT.txt', sep='\t')
}
#load in data---------------------------------------------------
gasTransfer <- read.table('NHD_gasTransfer_CT.txt', sep='\t')
#filter for channels with routed Q
channels <- read.table("C:\\Users\\craig\\Box Sync\\Ongoing Projects\\Watershed_Rules_of_Life\\Routing\\working\\channels.txt", sep = "" , header = FALSE)
colnames(channels)[colnames(channels)=="V12"] <- "n"
colnames(channels)[colnames(channels)=="V13"] <- "Width"
colnames(channels)[colnames(channels)=="V15"] <- "NHDPlusID"
View(channels)
channels <- channels[,c(12,13,15)]
getwd()
write.csv(channels, 'widths.csv')
#filter for channels with routed Q
channels <- read.table("C:\\Users\\craig\\Box Sync\\Ongoing Projects\\Watershed_Rules_of_Life\\Routing\\working\\channels.txt", sep = "" , header = FALSE)
colnames(channels)[colnames(channels)=="V13"] <- "Width"
colnames(channels)[colnames(channels)=="V15"] <- "NHDPlusID"
View(channels)
channels <- channels[,c(13,15)]
View(channels)
write.csv(channels, 'widths.csv')
getwd
getwd()
rm(channels)
#'Classify river for expert framework
#'
#'@param Wobs observed widths matrix
classify_func <- function(Wobs) {
lwbar <- mean(log(Wobs), na.rm=TRUE)#apply(log(Wobs), 1, mean, na.rm = TRUE)
lwsd <- sd(log(Wobs), na.rm= TRUE)#apply(log(Wobs), 1, sd, na.rm = TRUE)
maxWidth = 6.5
classes <- c(2.476118144,
2.864001065,
3.103015939,
3.249308032,
3.284178964,
3.371669039,
3.56827873,
3.664586762,
3.683922384,
4.002696788,
4.031559142,
4.357733942,
4.436574004,
4.921166637,
5.287893051) #median width of each river type
index <- ifelse(lwbar > maxWidth, 17, which.min(abs(classes-lwbar))) #17 for big rivers
index <- ifelse(lwsd >= 0.45, 16, index)  #16 for width-variable rivers, which overrides 'big' rivers
}
x <- cbind(c(40,30,40), c(30,34,35), c(50,40,40))
classify_func(x)
#'Classify river for expert framework
#'
#'@param Wobs observed widths matrix
classify_func <- function(Wobs) {
lwbar <- mean(log(Wobs), na.rm=TRUE)#apply(log(Wobs), 1, mean, na.rm = TRUE)
lwsd <- sd(log(Wobs), na.rm= TRUE)#apply(log(Wobs), 1, sd, na.rm = TRUE)
maxWidth = 6.5
classes <- c(2.476118144,
2.864001065,
3.103015939,
3.249308032,
3.284178964,
3.371669039,
3.56827873,
3.664586762,
3.683922384,
4.002696788,
4.031559142,
4.357733942,
4.436574004,
4.921166637,
5.287893051) #median width of each river type
index <- ifelse(lwbar > maxWidth, 17, which.min(abs(classes-lwbar))) #17 for big rivers
index <- ifelse(lwsd >= 0.45, 16, index)  #16 for width-variable rivers, which overrides 'big' rivers
return(index)
}
classify_func(x)
x <- x[1,]
classify_func(x)
#'Classify river for unsupervised framework
#'
#' @param Wobs observed widths matrix
classify_func_unsupervised <- function(Wobs) {
width <- median((Wobs)) #note these are not log widths!
width_sd <- sd((Wobs))
#One-vs-Rest Logistic regression model
#test set accuracy rate of 87%
p_noise <- 1 / (1.0 + exp(-(-3.12907956 + 7.72682055e-04 * width_sd + 1.68285442e-03 * width)))
p_1 <- 1 / (1.0 + exp(-(1.9719785 + -7.08487404e-04 * width_sd + -9.57359172e-04 * width)))
p_2 <- 1 / (1.0 + exp(-(-4.0504766  + -1.30605126e-04 * width_sd + 1.60069188e-03 * width)))
p_3<- 1 / (1.0 + exp(-(-4.34955267 + -6.70236303e-03 * width_sd + 7.59492911e-05 * width)))
p_4 <- 1 / (1.0 + exp(-(-3.9977568  + 3.24040207e-04 * width_sd + 1.59933716e-03 * width)))
p_5 <- 1 / (1.0 + exp(-(-4.26058253 + -2.39296957e-03 * width_sd + -1.41460664e-02 * width)))
p_6 <- 1 / (1.0 + exp(-(-3.86984885 + -2.63864258e-04 * width_sd + -1.68608848e-03 * width)))
p_7 <- 1 / (1.0 + exp(-(-1.15978639 + 5.68264551e-04 * width_sd + -1.27528508e-01 * width)))
probs <- data.frame(p_noise, p_1, p_2, p_3, p_4, p_5, p_6, p_7)
index <- which.max(probs)
index <- ifelse(index == 1, 101, index-1) #101 for 'noisey' rivers
return(index)
}
classify_func_unsupervised(x)
x = Wobs
Wobs <- x
width <- median((Wobs)) #note these are not log widths!
width_sd <- sd((Wobs))
#One-vs-Rest Logistic regression model
#test set accuracy rate of 87%
p_noise <- 1 / (1.0 + exp(-(-3.12907956 + 7.72682055e-04 * width_sd + 1.68285442e-03 * width)))
p_1 <- 1 / (1.0 + exp(-(1.9719785 + -7.08487404e-04 * width_sd + -9.57359172e-04 * width)))
p_2 <- 1 / (1.0 + exp(-(-4.0504766  + -1.30605126e-04 * width_sd + 1.60069188e-03 * width)))
p_3<- 1 / (1.0 + exp(-(-4.34955267 + -6.70236303e-03 * width_sd + 7.59492911e-05 * width)))
p_4 <- 1 / (1.0 + exp(-(-3.9977568  + 3.24040207e-04 * width_sd + 1.59933716e-03 * width)))
p_5 <- 1 / (1.0 + exp(-(-4.26058253 + -2.39296957e-03 * width_sd + -1.41460664e-02 * width)))
p_6 <- 1 / (1.0 + exp(-(-3.86984885 + -2.63864258e-04 * width_sd + -1.68608848e-03 * width)))
p_7 <- 1 / (1.0 + exp(-(-1.15978639 + 5.68264551e-04 * width_sd + -1.27528508e-01 * width)))
probs <- data.frame(p_noise, p_1, p_2, p_3, p_4, p_5, p_6, p_7)
View(probs)
index <- which.max(probs)
index
index[,1]
index[1]
pkgbuild::compile_dll() # see note below
roxygen2::roxygenise(load = "source")
usethis::use_pkgdown()
pkgdown::build_site()
exp(4.540631665)
roxygen2::roxygenise(load = "source")
pkgdown::build_site()
pkgbuild::compile_dll() # see note below
pkgbuild::compile_dll() # see note below
pkgbuild::compile_dll() # see note below
pkgbuild::compile_dll() # see note below
roxygen2::roxygenise(load = "source")
pkgdown::build_site()
pkgbuild::compile_dll() # see note below
roxygen2::roxygenise(load = "source")
pkgdown::build_site()
